{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                        \n",
    "from pytrends.request import TrendReq\n",
    "pytrend = TrendReq()\n",
    "import regex as re\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "import requests\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy as tp\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "bearerToken = \"AAAAAAAAAAAAAAAAAAAAAOUBZwEAAAAAuSI9Lk9VJF5p8oZ60%2Ffnb25FSXo%3DsH2SwTWEqpQOe0acAUZeAiPdazuwZYetImYMSn9Wzk7dmXR1VV\"\n",
    "\n",
    "client = tp.Client(bearer_token=bearerToken, wait_on_rate_limit=True)\n",
    "\n",
    "def convertDate(tweetObject):\n",
    "    tweetDate = tweetObject['created_at']\n",
    "    tweetDate = tweetDate.replace(\"T\", \" \")\n",
    "    tweetDate = str(tweetDate.split(\".\")[0])\n",
    "    tweetDate = datetime.strptime(tweetDate, '%Y-%m-%d %H:%M:%S')\n",
    "    return(tweetDate)\n",
    "\n",
    "\n",
    "\n",
    "def convertTime(inputDate):\n",
    "\n",
    "    inputDateSplit = inputDate.split(\"-\")\n",
    "\n",
    "    year = int(inputDateSplit[0])\n",
    "    month = int(inputDateSplit[1])\n",
    "    day = int(inputDateSplit[2])\n",
    "\n",
    "    if month < 10 and day < 10:\n",
    "        timeString = f\"{year}-0{month}-0{day}T00:00:00Z\"\n",
    "        return timeString\n",
    "    elif month < 10 and day >= 10:\n",
    "        timeString = f\"{year}-0{month}-{day}T00:00:00Z\"\n",
    "        return timeString\n",
    "    elif month >= 10 and day < 10:\n",
    "        timeString = f\"{year}-{month}-0{day}T00:00:00Z\"\n",
    "        return timeString\n",
    "    else:\n",
    "        timeString = f\"{year}-{month}-{day}T00:00:00Z\"\n",
    "        return timeString\n",
    "\n",
    "def generateTweets(date, df, brand):\n",
    "\n",
    "    tweets = client.search_recent_tweets(query=f\"{brand} -is:retweet lang:EN\", tweet_fields=['context_annotations', 'created_at', 'text', 'author_id', 'source', 'public_metrics'], max_results=100, end_time=date)\n",
    "        \n",
    "    for tweet in tweets.data:\n",
    "        tweet_ID = tweet.id\n",
    "        tweet_content = tweet.text\n",
    "        tweet_date = tweet.created_at\n",
    "        tweet_retweets = tweet.public_metrics['retweet_count']\n",
    "        tweet_replies = tweet.public_metrics['reply_count']\n",
    "        tweet_likes = tweet.public_metrics['like_count']\n",
    "        tweet_quotes = tweet.public_metrics['quote_count']\n",
    "\n",
    "        df = df.append({'id': str(tweet_ID), 'full_text':str(tweet_content), 'created_at':tweet_date,  \\\n",
    "                'rt_count':tweet_retweets, 're_count':tweet_replies, 'like_count':tweet_likes, 'quotes':tweet_quotes}, ignore_index=True)\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "def filterItems(topTenList):\n",
    "    filteredItems = []\n",
    "    for item in topTenList:\n",
    "    # itemToTest = topTenList[1]\n",
    "        pytrend.build_payload([item], timeframe='today 1-m')\n",
    "        relatedTopics = pytrend.related_topics()\n",
    "        try:\n",
    "            relatedTopicList = list(relatedTopics[item]['top']['topic_type'][:5])\n",
    "            relatedTopicList = [x.lower() for x in relatedTopicList]\n",
    "            if \"food\" in relatedTopicList or \"drink\" in relatedTopicList or \"beverage\" in relatedTopicList:\n",
    "                filteredItems.append(item)\n",
    "        except Exception as e:\n",
    "            # print(e, item)\n",
    "            None\n",
    "\n",
    "    return filteredItems\n",
    "\n",
    "\n",
    "def generateDF(phrase):\n",
    "    df = pd.DataFrame(columns=['id', 'full_text', 'created_at', 'rt_count', 're_count', 'like_count', 'quotes'])\n",
    "\n",
    "    \n",
    "    for i in range(6):\n",
    "        date = convertTime((datetime.now() - timedelta(days=i)).strftime(\"%Y-%m-%d\"))\n",
    "        \n",
    "        df = generateTweets(date, df, phrase)\n",
    "\n",
    "    df.drop_duplicates(subset=\"id\", inplace=True)\n",
    "\n",
    "    regexStart = str(phrase.split(\" \")[-1])\n",
    "    regexStart = regexStart.replace('\"', '')\n",
    "\n",
    "    df[\"trending_product\"] = \"null\"\n",
    "    for a, tweet in enumerate(df.full_text):\n",
    "        regex = re.search(fr'{regexStart}(..*)', tweet)\n",
    "        try:\n",
    "            df[\"trending_product\"][a] = regex.group(1)\n",
    "        except AttributeError:\n",
    "            df[\"trending_product\"][a] = regex\n",
    "\n",
    "    \n",
    "    df['trending_product'] = df['trending_product'].apply(lambda x: \" \".join(str(x).split(\" \")[1:3]))\n",
    "    df = df[df.trending_product.str.len() > 3]\n",
    "    df['trending_product'] = df['trending_product'].apply(lambda x: str(x).lower())\n",
    "    df['trending_product'] = df['trending_product'].apply(lambda x: str(x).replace(\"@\", \"\"))\n",
    "\n",
    "    return df\n",
    "\n",
    "def generateTopTen(productList):\n",
    "\n",
    "    topTen = Counter(productList).most_common(20)\n",
    "\n",
    "    topTenList = []\n",
    "    for item in topTen:\n",
    "        if item != \"null\":\n",
    "            topTenList.append(item[0])\n",
    "\n",
    "    return(topTenList)\n",
    "\n",
    "def googleTrendTopics(topList):\n",
    "    filteredItems = []\n",
    "    for item in topList:\n",
    "    # itemToTest = topTenList[1]\n",
    "        pytrend.build_payload([item], timeframe='today 1-m')\n",
    "        relatedTopics = pytrend.related_topics()\n",
    "        try:\n",
    "            relatedTopicList = list(relatedTopics[item]['top']['topic_type'][:5])\n",
    "            relatedTopicListLower = [x.lower() for x in relatedTopicList]\n",
    "            relatedTopicListLower = list(relatedTopicListLower)\n",
    "            if \"food\" in relatedTopicListLower or \"drink\" in relatedTopicListLower or \"beverage\" in relatedTopicListLower:\n",
    "                filteredItems.append(item)\n",
    "        except Exception as e:\n",
    "            # print(e, item)\n",
    "            None\n",
    "\n",
    "    return(filteredItems)\n",
    "\n",
    "\n",
    "def generateNews(brandName):\n",
    "    urlBrandName = \"+\".join(brandName.split(\" \"))\n",
    "\n",
    "    URL = f\"https://news.google.com/search?q={urlBrandName}&hl=en-US&gl=US&ceid=US:en\"\n",
    "    \n",
    "    HEADERS = ({'User-Agent':\n",
    "                'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 \\\n",
    "                (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\\\n",
    "                'Accept-Language': 'en-US, en;q=0.5'})\n",
    "    \n",
    "    webpage = requests.get(URL, headers=HEADERS)\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "    news = soup.find_all(\"a\", class_=\"DY5T1d\")\n",
    "\n",
    "    for article in news:\n",
    "        regex = r\"href=\\\".(..*)\\\"\"\n",
    "\n",
    "        articleText = article.text.lower()\n",
    "        articleText = articleText.replace(\"'s\", \"\")\n",
    "        if brandName in articleText or \"-\".join(brandName.split(\" \")) in articleText:\n",
    "            # print(article.text.lower())\n",
    "            url = re.findall(regex, str(article), re.MULTILINE)[0]\n",
    "            return(articleText, url)\n",
    "\n",
    "\n",
    "def generateTrendingProducts(useCustomDF=False, df1=None, df2=None):\n",
    "\n",
    "    productList = []\n",
    "    phrases = ['\"tried the new\"', '\"has anyone tried\"']\n",
    "\n",
    "    if useCustomDF == False:\n",
    "        for phrase in phrases:\n",
    "\n",
    "            df_phrase = generateDF(phrase)\n",
    "            productList = productList + list(df_phrase.trending_product)\n",
    "\n",
    "    else:\n",
    "        productList = list(df1.trending_product) + list(df2.trending_product)\n",
    "\n",
    "\n",
    "    topTenList = generateTopTen(productList)\n",
    "\n",
    "    filteredList = googleTrendTopics(topTenList)\n",
    "    trendingArticleNames = []\n",
    "    trendingURLNames = []\n",
    "    for item in filteredList:\n",
    "        try:\n",
    "            trendingText, trendingURL = generateNews(item)\n",
    "            trendingArticleNames.append(trendingText)\n",
    "\n",
    "            newsUrl = f\"https://news.google.com{trendingURL}\"\n",
    "            r = requests.get(newsUrl, allow_redirects=False)\n",
    "            urlFix = r.headers['Location']\n",
    "            r2 = requests.get(urlFix, allow_redirects=False)\n",
    "\n",
    "            trendingURLNames.append(r2.headers['Location'])\n",
    "        \n",
    "        except:\n",
    "            None\n",
    "\n",
    "    return(trendingArticleNames, trendingURLNames)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfTest1 = pd.read_excel(\"/Users/vetlefrantzvaag/Desktop/DashThesis/multipage/data/tried_new_20.05.xlsx\", engine=\"openpyxl\", index_col=[0])\n",
    "dfTest2 = pd.read_excel(\"/Users/vetlefrantzvaag/Desktop/DashThesis/multipage/data/tried_anyone_20.05.xlsx\", engine=\"openpyxl\", index_col=[0])\n",
    "\n",
    "articleName, urlName = generateTrendingProducts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mountain dew will be bringing back its typhoon flavor',\n",
       " 'sweet, spicy and sour: john chantarasak’s recipes for thai salads',\n",
       " 'sixpoint brewery & mike hot honey release slice sipper']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1: hard mountain dew comes to minnesota\n"
     ]
    }
   ],
   "source": [
    "for i, article in enumerate(trendingArticles):\n",
    "    print(f\"#{i+1}: {article}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tried_anyone = df_tried_anyone[['id', 'full_text', 'trending_product']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tried_anyone.to_excel(\"tried_anyone_20.05.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\"Nitro pepsi\"</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geoName</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canada</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mexico</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netherlands</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Norway</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poland</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Korea</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United Kingdom</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                \"Nitro pepsi\"\n",
       "geoName                      \n",
       "Australia                  10\n",
       "Canada                     18\n",
       "Mexico                      4\n",
       "Netherlands                 2\n",
       "Norway                      7\n",
       "Poland                      8\n",
       "South Korea                 6\n",
       "United Kingdom              4\n",
       "United States             100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the libraries\n",
    "import pandas as pd                        \n",
    "from pytrends.request import TrendReq\n",
    "pytrend = TrendReq()\n",
    "\n",
    "#provide your search terms\n",
    "kw_list=['\"Nitro pepsi\"']\n",
    "\n",
    "#search interest per region\n",
    "#run model for keywords (can also be competitors)\n",
    "pytrend.build_payload(kw_list, timeframe='today 1-m')\n",
    "\n",
    "# Interest by Region\n",
    "regiondf = pytrend.interest_by_region()\n",
    "#looking at rows where all values are not equal to 0\n",
    "regiondf = regiondf[(regiondf != 0).all(1)]\n",
    "\n",
    "#drop all rows that have null values in all columns\n",
    "regiondf.dropna(how='all',axis=0, inplace=True)\n",
    "\n",
    "# #visualise\n",
    "# regiondf.plot(figsize=(20, 12), y=kw_list, kind ='bar')\n",
    "regiondf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"pepsi nitro\"\n"
     ]
    }
   ],
   "source": [
    "brand = \"pepsi nitro\"\n",
    "brandSplit = brand.split(\" \")\n",
    "\n",
    "if len(brandSplit) > 1:\n",
    "    brand = f'\"{\" \".join(brandSplit)}\"'\n",
    "\n",
    "print(brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4598b9d37a0cfcf13072dd1c1a2967ee736f9b9c803d9c409850d61e833e89a0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
